# video-to-prompt-tool
video
import streamlit as st
import cv2
import tempfile
import google.generativeai as genai
from PIL import Image
import os
import time

# é¡µé¢é…ç½®
st.set_page_config(page_title="AI åˆ†é•œåæ¨å·¥å…·", layout="wide", page_icon="ğŸ¬")

# è‡ªå®šä¹‰CSSè®©ç•Œé¢æ›´åƒä¸“ä¸šSaaSå·¥å…·
st.markdown("""
<style>
    .stButton>button {width: 100%; border-radius: 5px; height: 3em; background-color: #FF4B4B; color: white;}
    .reportview-container {background: #f0f2f6;}
</style>
""", unsafe_allow_html=True)

# æ ¸å¿ƒå‡½æ•°ï¼šæå–å…³é”®å¸§
def extract_frames(video_path, interval_sec=2):
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    frames = []
    timestamps = []
    
    current_frame = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        
        if int(current_frame % (int(fps) * interval_sec)) == 0:
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            frames.append(Image.fromarray(frame_rgb))
            timestamps.append(current_frame / fps)
            
        current_frame += 1
    cap.release()
    return frames, timestamps

# æ ¸å¿ƒå‡½æ•°ï¼šAIåˆ†æ
def analyze_image(image, api_key):
    genai.configure(api_key=api_key)
    # ä½¿ç”¨ Flash æ¨¡å‹ï¼Œé€Ÿåº¦å¿«ä¸”å…è´¹é¢åº¦é«˜
    model = genai.GenerativeModel('gemini-1.5-flash') 
    
    prompt = """
    Analyze this movie frame. Provide a concise prompting description for AI image generation (like Midjourney).
    Format: [Subject/Action], [Camera Angle/Shot Type], [Lighting/Atmosphere], [Art Style/Texture].
    Keep it strictly descriptive, comma-separated.
    """
    try:
        response = model.generate_content([prompt, image])
        return response.text
    except Exception as e:
        return "Error analyzing frame."

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.title("ğŸ› ï¸ å·¥å…·è®¾ç½®")
    # å¯ä»¥åœ¨è¿™é‡Œé¢„åŸ‹ä½ çš„Keyï¼Œæˆ–è€…è®©ç”¨æˆ·è¾“å…¥
    api_key = st.text_input("Gemini API Key", type="password", help="å¦‚æœæ²¡æœ‰ï¼Œå» Google AI Studio ç”³è¯·å…è´¹ç‰ˆ")
    interval = st.slider("æŠ½å¸§é—´éš” (ç§’)", 1, 10, 3)
    st.markdown("---")
    st.markdown("**å…³äºå·¥å…·**\n\næ­¤å·¥å…·ç”¨äºå¿«é€Ÿæ‹†è§£è§†é¢‘åˆ†é•œï¼Œå¹¶åæ¨ AIGC æç¤ºè¯ã€‚")

# --- ä¸»ç•Œé¢ ---
st.title("ğŸ¬ è§†é¢‘æ™ºèƒ½åˆ†é•œ & Prompt åæ¨")

uploaded_file = st.file_uploader("æ‹–å…¥å‚è€ƒè§†é¢‘ (MP4/MOV)", type=["mp4", "mov"])

if uploaded_file and st.button("å¼€å§‹æ™ºèƒ½åˆ†æ"):
    if not api_key:
        st.warning("è¯·å…ˆåœ¨å·¦ä¾§è¾“å…¥ API Key")
        st.stop()

    # ä¸´æ—¶ä¿å­˜è§†é¢‘ä»¥ä¾› OpenCV è¯»å–
    tfile = tempfile.NamedTemporaryFile(delete=False) 
    tfile.write(uploaded_file.read())
    
    with st.spinner('æ­£åœ¨æ‹†è§£åˆ†é•œ...'):
        frames, timestamps = extract_frames(tfile.name, interval)
    
    st.success(f"æ‹†è§£å®Œæˆï¼Œå…± {len(frames)} ä¸ªå…³é”®å¸§ã€‚æ­£åœ¨è°ƒç”¨ AI åˆ†æ...")
    
    # è¿›åº¦æ¡
    progress_bar = st.progress(0)
    
    # ç»“æœå±•ç¤ºåŒº
    for i, (frame, ts) in enumerate(zip(frames, timestamps)):
        with st.container():
            col1, col2 = st.columns([1, 2])
            with col1:
                st.image(frame, use_column_width=True, caption=f"â±ï¸ {ts:.1f}s")
            with col2:
                result = analyze_image(frame, api_key)
                st.markdown(f"**Keyframe #{i+1} Prompt:**")
                st.code(result, language="text")
        
        st.divider()
        progress_bar.progress((i + 1) / len(frames))
    
    os.remove(tfile.name) # æ¸…ç†åƒåœ¾
    streamlit
opencv-python-headless
google-generativeai
Pillow
numpy
